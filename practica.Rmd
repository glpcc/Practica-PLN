---
title: "Practica"
output: pdf_document
date: "2022-11-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Inicializacion

Cargo el pacquete rjson para luego carga los articulos
```{r instalar_rjson}
if (! require('rjson')){
  !install.packages('rjson');
}
library('rjson');
```

Cargo el json con los articulos (durante las pruebas el reducido)
```{r cargar_json}
f = fromJSON(file = 'reduced_article_list2.json');
ids = unlist(lapply(f$articles, function (x) x$id ));
titulos = unlist(lapply(f$articles, function (x) x$title ));
ano = unlist(lapply(f$articles, function (x) x$year ));
texto = unlist(lapply(f$articles, function (x) x$abstractText ));
df = data.frame(ids,titulos,ano,texto)
```
Ahora lo que vamos a hacer es buscar los afijos que nos sirvan para clasificar.

Test udpipe
```{r}
library(udpipe)
# udpipe_download_model(language = "spanish-ancora") #"spanish-ancora" or "spanish-gsd"
#Descarga "spanish-ancora-ud-2.5-191206.udpipe"
udmodel_es<-udpipe_load_model(file = 'spanish-ancora-ud-2.5-191206.udpipe');
```

```{r}
test = as.data.frame(udpipe_annotate(udmodel_es,'Mi perro tiene conjuntibitis severa en los ojos'))
```

Test conseguir enfermedades
```{r}
library(stringr)
```


```{r}
# Modo texto a texto
a = Sys.time()
enfermedades = c();
for (texto in df$texto){
  texto_analizado = as.data.frame(udpipe_annotate(udmodel_es,texto));
  posibles_enfermedades = str_detect(texto_analizado$token,regex('.*?itis$|.*?oma$|.*?algia$|^hipo.*|^hiper.*'))
  for (j in 1:nrow(texto_analizado)){
    if (texto_analizado$upos[[j]] == 'NOUN' & posibles_enfermedades[[j]]){
      if (texto_analizado$dep_rel[[j+1]] == 'amod'){
        # print(paste(texto_analizado$token[[j]], texto_analizado$token[[j+1]],sep = " "))
        enfermedades = c(enfermedades,paste(texto_analizado$token[[j]], texto_analizado$token[[j+1]],sep = " ") )
      }else{
        # print(texto_analizado$token[[j]])
        enfermedades = c(enfermedades,texto_analizado$token[[j]])
      }
    }
  }
}
enfermedades = unique(enfermedades)
print(Sys.time() - a)
enfermedades
```

```{r}
# Modo dataframe entero
a = Sys.time()
enfermedades = c();
test = as.data.frame(udpipe_annotate(udmodel_es,df$texto))
posibles_enfermedades = str_detect(test$token,regex('.*?itis$|.*?oma$|.*?algia$|^hipo.*|^hiper.*'))
for (j in 1:nrow(test)){
  if (test$upos[[j]] == 'NOUN' & posibles_enfermedades[[j]]){
    if (test$dep_rel[[j+1]] == 'amod'){
      # print(paste(texto_analizado$token[[j]], texto_analizado$token[[j+1]],sep = " "))
      enfermedades = c(enfermedades,paste(test$token[[j]], test$token[[j+1]],sep = " ") )
    }else{
      # print(texto_analizado$token[[j]])
      enfermedades = c(enfermedades,test$token[[j]])
    }
  }
}
enfermedades = unique(enfermedades)
print(Sys.time() - a)
enfermedades
```

Separamos las palabras compuestas para que el diccionario pueda buscarlas.

```{r separar}
enfermedades2 = c()
for (i in 1:length(enfermedades)){
  enfermedades2[i] = str_extract(enfermedades[i], "^\\w+")
}
enfermedades2
```

Hacemos la búsqueda en el diccionario médico para verificar

```{r buscador, warning=FALSE}
library(stringi)
urls = c()
valid_urls = c()
enfermedades3 = c()
for (i in 1:length(enfermedades)){
  url = "https://www.cun.es/diccionario-medico/terminos/"
  urlOK = paste(url, enfermedades2[i])
  urlOK = stri_replace_all_regex(urlOK, c(" ", "á", "é", "í", "ó", "ú"), c("", "a", "e", "i", "o", "u"), vectorize_all = FALSE)
  urls[i] = urlOK
  tryCatch(
  {
    lines = readLines(con=urlOK, warn = FALSE)
    enfermedades3 = c(enfermedades3, enfermedades[i])
    valid_urls = c(valid_urls, urlOK)
  },
  error=function(cond){
    message(paste("URL no existe:", urlOK))
    return(NA)
  }
)
}
enfermedades3
```
Una vez que ya tenemos las enfermedades buscadas en el diccionario, vamos a lematizarlas. Para ello, primero vamos a inicializar spacyR.
```{r inicio, warning=FALSE, message=FALSE}
library(spacyr)
spacy_initialize(model = "es_core_news_sm")
```

Una vez inicializado, vamos a lematizar:
```{r lema}
res <- spacy_parse(enfermedades3, pos = FALSE, lemma = TRUE, entity = FALSE)
res[, c("token", "lemma")]
```
```{r}
url_base = "https://www.cun.es/diccionario-medico/terminos/"
definiciones = c()
for (i in 1:length(valid_urls)){
  lines = readLines(valid_urls[i],
encoding = "UTF-8")
  definicion = lines[891]
  tildes1 <- gsub('&aacute;', 'á', definicion)
tildes2 <- gsub('&eacute;', 'é', tildes1)
tildes3 <- gsub('&iacute;', 'í', tildes2)
tildes4 <- gsub('&oacute;', 'ó', tildes3)
tildes5 <- gsub('&uacute;', 'ú', tildes4)
eñes <- gsub('&ntilde;', 'ñ', tildes5)
eñes1 <- gsub('&Ntilde;', 'Ñ', eñes)
quest <- gsub('&iquest;', '¿', eñes1)
excl <- gsub('&iexcl;', '¡', quest)
espacios <- trimws(excl)
definicionOK<- stri_replace_all_regex(espacios, '<.*?>', '', vectorize_all = FALSE)
  definiciones = c(definiciones, definicionOK)
}
names(definiciones) = enfermedades3
```
