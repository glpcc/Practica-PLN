---
title: "Practica"
output: pdf_document
date: "2022-11-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Inicializacion

Cargo el pacquete rjson para luego carga los articulos
```{r instalar_rjson}
if (! require('rjson')){
  !install.packages('rjson');
}
library('rjson');
```

Cargo el json con los articulos (durante las pruebas el reducido)
```{r cargar_json}
f = fromJSON(file = 'reduced_article_list2.json');
ids = unlist(lapply(f$articles, function (x) x$id ));
titulos = unlist(lapply(f$articles, function (x) x$title ));
ano = unlist(lapply(f$articles, function (x) x$year ));
texto = unlist(lapply(f$articles, function (x) x$abstractText ));
df = data.frame(ids,titulos,ano,texto)
```
Ahora lo que vamos a hacer es buscar los afijos que nos sirvan para clasificar.

Test udpipe
```{r}
library(udpipe)
# udpipe_download_model(language = "spanish-ancora") #"spanish-ancora" or "spanish-gsd"
#Descarga "spanish-ancora-ud-2.5-191206.udpipe"
udmodel_es<-udpipe_load_model(file = 'spanish-ancora-ud-2.5-191206.udpipe');
```

```{r}
test = as.data.frame(udpipe_annotate(udmodel_es,'Mi perro tiene conjuntibitis severa en los ojos'))
```

Test conseguir enfermedades
```{r}
library(stringr)
```


```{r}
# Modo texto a texto
a = Sys.time()
enfermedades = c();
for (texto in df$texto){
  texto_analizado = as.data.frame(udpipe_annotate(udmodel_es,texto));
  posibles_enfermedades = str_detect(texto_analizado$token,regex('.*?itis$|.*?oma$|.*?algia$|^hipo.*|^hiper.*'))
  for (j in 1:nrow(texto_analizado)){
    if (texto_analizado$upos[[j]] == 'NOUN' & posibles_enfermedades[[j]]){
      if (texto_analizado$dep_rel[[j+1]] == 'amod'){
        # print(paste(texto_analizado$token[[j]], texto_analizado$token[[j+1]],sep = " "))
        enfermedades = c(enfermedades,paste(texto_analizado$token[[j]], texto_analizado$token[[j+1]],sep = " ") )
      }else{
        # print(texto_analizado$token[[j]])
        enfermedades = c(enfermedades,texto_analizado$token[[j]])
      }
    }
  }
}
enfermedades = unique(enfermedades)
print(Sys.time() - a)
enfermedades = sort(enfermedades)
enfermedades
```

```{r}
# Modo dataframe entero
a = Sys.time()
enfermedades = c();
test = as.data.frame(udpipe_annotate(udmodel_es,df$texto))
posibles_enfermedades = str_detect(test$token,regex('.*?itis$|.*?oma$|.*?algia$|^hipo.*|^hiper.*'))
for (j in 1:nrow(test)){
  if (test$upos[[j]] == 'NOUN' & posibles_enfermedades[[j]]){
    if (test$dep_rel[[j+1]] == 'amod'){
      # print(paste(texto_analizado$token[[j]], texto_analizado$token[[j+1]],sep = " "))
      enfermedades = c(enfermedades,paste(test$token[[j]], test$token[[j+1]],sep = " ") )
    }else{
      # print(texto_analizado$token[[j]])
      enfermedades = c(enfermedades,test$token[[j]])
    }
  }
}
enfermedades = unique(enfermedades)
print(Sys.time() - a)
enfermedades = sort(enfermedades)
enfermedades
```

Separamos las palabras compuestas para que el diccionario pueda buscarlas.

```{r separar}
enfermedades2 = c()
for (i in 1:length(enfermedades)){
  enfermedades2[i] = str_extract(enfermedades[i], "^\\w+")
}

enfermedades2 = unique(enfermedades2)
enfermedades2
```

Hacemos la búsqueda en el diccionario médico para verificar

```{r buscador, warning=FALSE}
library(stringi)
urls = c()
valid_urls = c()
enfermedades3 = c()
for (i in 1:length(enfermedades2)){
  url = "https://www.cun.es/diccionario-medico/terminos/"
  urlOK = paste(url, enfermedades2[i])
  urlOK = stri_replace_all_regex(urlOK, c(" ", "á", "é", "í", "ó", "ú"), c("", "a", "e", "i", "o", "u"), vectorize_all = FALSE)
  urls[i] = urlOK
  tryCatch(
  {
    lines = readLines(con=urlOK, warn = FALSE)
    enfermedades3 = c(enfermedades3, enfermedades2[i])
    valid_urls = c(valid_urls, urlOK)
  },
  error=function(cond){
    message(paste("URL no existe:", urlOK))
    return(NA)
  }
)
}
enfermedades3
```

Una vez que ya tenemos las enfermedades buscadas en el diccionario, vamos a lematizarlas. Para ello, primero vamos a inicializar spacyR.

```{r inicio, warning=FALSE, message=FALSE}
library(spacyr)
spacy_initialize(model = "es_core_news_sm")
```
Una vez inicializado, vamos a lematizar. Para lematizar, spacy_parse no acaba de lematizar bien, por tanto para sacar la forma invariable de las enfermedades, vamos a quitar los prefijos y sufijos.
```{r lema}
forma_invariable <- stri_replace_all_regex(enfermedades3, "hipo|hiper|itis|algia|algia|oma","")

```

```{r 2}
res <- spacy_parse(forma_invariable, pos = FALSE, lemma = TRUE, entity = FALSE)
res[, c("token", "lemma")]
```

```{r, warning=FALSE}
limpiaBloquesConTrim <- function(vec_cadenas){
a <- gsub("<[^<>]*>", "", vec_cadenas)
trimws(a)}

reemplazaElemsHTML <- function(vec_cadenas){
traduc <- list(c("&aacute;", "á"),
               c("&Aacute;", "Á"),
               c("&eacute;", "e"),
               c("&Eacute;", "É"),
               c("&iacute;", "í"),
               c("&Iacute;", "Í"),
               c("&oacute;", "ó"),
               c("&Oacute;", "Ó"),
               c("&uacute;", "ú"),
               c("&Uacute;", "Ú"),
               c("&ntilde;", "ñ"),
               c("&Ntilde;", "Ñ"),
               c("&iquest;", "¿"),
               c("&iexcl;", "¡"),
               c("&laquo;", "«"),
               c("&raquo;", "»"))

stri_replace_all_regex(vec_cadenas,
                       pattern=unlist(lapply(traduc, function(x){x[1]})),
                       replacement=unlist(lapply(traduc, function(x){x[2]})),
                       vectorize=FALSE)
}

url_base = "https://www.cun.es/diccionario-medico/terminos/"
definiciones = c()
for (i in 1:length(valid_urls)){
  lines = readLines(valid_urls[i],
                    encoding = "UTF-8")
  definicion = lines[891]
  definicion <- limpiaBloquesConTrim(lines[891])
  definicionOK <- reemplazaElemsHTML(definicion)
  definiciones = c(definiciones, definicionOK)
}
names(definiciones) = enfermedades3
```

Creamos un archivo de texto para introducir todas las definiciones.

```{r txt}
con1 <- file(
  description = "Definiciones.txt",
  open = "wt",
  encoding = "UTF-8")

for (i in 1:length(definiciones)){
  definicionFinal = paste(names(definiciones[i]), ": ", definiciones[i], sep="")
  writeLines(definicionFinal, con1)
  variaciones = unlist(str_extract_all(enfermedades, paste(names(definiciones[i]), ".*")))
  if (length(variaciones) > 1){
    variaciones = paste("Variaciones:", paste(as.character(variaciones), collapse = ", "))
    writeLines(variaciones, con1)
  }
  writeLines("\n", con1)
}

close(con1)
```

